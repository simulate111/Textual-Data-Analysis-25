{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA/lMKd6GglTV9KxkYQMRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Textual-Data-Analysis-25/blob/main/Exercise_13_(solution)_example_discussion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This (somewhat doomsday) paper summarizes a set of experiments on LLMs which take what we saw on the lecture a step further to achieve a particular outcome: https://arxiv.org/pdf/2412.12140 . Read the paper (including the fascinating appendix) and ponder the following:\n",
        "\n",
        "(1) The complexity and structure of the agent scaffolding, detailed in Fig 3 and the surrounding discussion. How does this relate to what we discussed about prompts as discussed during the lecture?\n",
        "\n",
        "(2) Given what you know about dspy, do you think it would be very difficult to replicate the experiment in this paper?\n",
        "\n",
        "(3) Does in your view the paper warrant the alarming conclusions?\n",
        "\n",
        "Filip's take on this:\n",
        "\n",
        "Ad 1) The scaffolding was in my view the most interesting part of the paper. It demonstrated many of the concepts we discussed during the lecture, especially in terms of \"Chain-of-Thought\". The agent scaffolding decomposes the problem into palatable steps for the model, leads its inference and maintains its relevant memory. It also maintains a reasoning loop for the model. It is excessively unlikely that the model would be able to solve the task with a simple prompt.\n",
        "\n",
        "Ad 2) I would be rather optimistic about being able to implement a simple version of this scaffolding in DSPy. Especially as the forward() method allows doing arbitrary computations, such as calling tools, etc. Of course prompt optimizing would then be very expensive and quite hard. But I do believe a simple version could be put up in few hours of coding.\n",
        "\n",
        "Ad 3) I think the paper exaggerates the danger a little bit. The behavior seems to me akin to early computer viruses which copied themselves, except here the adaptation is left to the model. During the solution, the model did not do anything we would not have known it to be quite capable of. Many people use the models to debug issues (for the better or the worse, however you look at it). That said, it is still a remarkable achievement for sure."
      ],
      "metadata": {
        "id": "VC40Kvkmcerp"
      }
    }
  ]
}