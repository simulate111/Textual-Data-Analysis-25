{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh7R90Y6ZdrjG+IrdU2DjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Textual-Data-Analysis-25/blob/main/Exercise%20task%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_NhW72Y41Fe",
        "outputId": "59e840a9-4bb3-45c3-d1d2-adf0085734e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akb8HGoK29r7",
        "outputId": "681fd47f-547e-43dc-b3f3-f57584514475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "imdb = load_dataset('stanfordnlp/imdb', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPPBe4N77Eq_",
        "outputId": "89a05ea6-f79e-47fd-cc29-6e5473856607"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What NLP task is the dataset intended for (e.g. syntactic analysis, toxicity detection, etc.)? (You may need to refer to the documentation of the dataset for this.)\n",
        "Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. Data is used to classify reviews as positive or negative.\n",
        "\n",
        "What parts is the dataset split into (e.g. train, test) and how many examples does each contain?\n",
        "train\t25000\n",
        "unsupervised 50000\n",
        "test 25000\n",
        "\n",
        "What features (e.g. text, label) does the dataset have? (Try to understand how these relate to the NLP task the dataset is intended for.)\n",
        "text: a string feature, which is the user reviews.\n",
        "label: a classification label, with possible values including neg (0), pos (1).\n",
        "\n",
        "What is the first item in the training set of the dataset?\n",
        "'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967."
      ],
      "metadata": {
        "id": "eCLgUYYs5bLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "conll2003 = load_dataset('eriktks/conll2003', split='train')"
      ],
      "metadata": {
        "id": "uMizCFPM5E3c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conll2003[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOMX56LU7MvC",
        "outputId": "f55b23dd-e44f-4201-a1f9-f3692a8275e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What NLP task is the dataset intended for (e.g. syntactic analysis, toxicity detection, etc.)? (You may need to refer to the documentation of the dataset for this.)\n",
        "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups\n",
        "\n",
        "What parts is the dataset split into (e.g. train, test) and how many examples does each contain?\n",
        "train\t14041\n",
        "validation 3250\n",
        "test 3453\n",
        "\n",
        "What features (e.g. text, label) does the dataset have? (Try to understand how these relate to the NLP task the dataset is intended for.)\n",
        "The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag.\n",
        "\n",
        "What is the first item in the training set of the dataset?\n",
        "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ],
      "metadata": {
        "id": "CfkjYqCI5cGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "gsm8k = load_dataset('openai/gsm8k', 'main', split='train')"
      ],
      "metadata": {
        "id": "uE6IC9z95FHS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gsm8k[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKLkLKv-73vU",
        "outputId": "173458ae-5314-4c04-b107-00098806b14f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What NLP task is the dataset intended for (e.g. syntactic analysis, toxicity detection, etc.)? (You may need to refer to the documentation of the dataset for this.)\n",
        "GSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n",
        "\n",
        "What parts is the dataset split into (e.g. train, test) and how many examples does each contain?\n",
        "name    \ttrain\t  validation\n",
        "main    \t 7473\t   1319\n",
        "socratic\t 7473\t   1319\n",
        "\n",
        "What features (e.g. text, label) does the dataset have? (Try to understand how these relate to the NLP task the dataset is intended for.)\n",
        "For the main configuration, each instance contains a string for the grade-school level math question and a string for the corresponding answer with multiple steps of reasoning and calculator annotations\n",
        "\n",
        "For the socratic configuration, each instance contains a string for a grade-school level math question, a string for the corresponding answer with multiple steps of reasoning, calculator annotations, and Socratic sub-questions.\n",
        "\n",
        "What is the first item in the training set of the dataset?\n",
        "'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May."
      ],
      "metadata": {
        "id": "zKgxdnSQ5dmc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NoSCe_Z85FL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dl.turkunlp.org/TKO_8964_2023/news-en-2021.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Z8ZiNE8ypI",
        "outputId": "4c9abbfc-b3fc-4781-a2b5-919f9534261a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 11:28:49--  http://dl.turkunlp.org/TKO_8964_2023/news-en-2021.jsonl\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3385882 (3.2M) [application/octet-stream]\n",
            "Saving to: ‘news-en-2021.jsonl.1’\n",
            "\n",
            "news-en-2021.jsonl. 100%[===================>]   3.23M  2.02MB/s    in 1.6s    \n",
            "\n",
            "2025-01-17 11:28:51 (2.02 MB/s) - ‘news-en-2021.jsonl.1’ saved [3385882/3385882]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('json', data_files='news-en-2021.jsonl')"
      ],
      "metadata": {
        "id": "DxFaJCZ28-9w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjFxpRzEBUeJ",
        "outputId": "a93b5455-7670-4854-b489-821dd3074240"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wd-RDT796uB",
        "outputId": "f8351c1d-566f-4acd-99d2-be14bef93af5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'summary': 'The decisions follow a meeting of government ministers at the House of the Estates on Thursday afternoon.', 'tags': ['Kotimaan uutiset'], 'text': 'Finland\\'s government is pushing ahead with plans to introduce a Covid pass, following a meeting of ministers at the House of the Estates in Helsinki on Thursday afternoon. \\n \"There are still many open questions that need to be answered. At this point, it is impossible to promise that the pass will come or when it will come,\" Prime Minister  Sanna Marin  (SDP) told the media following the conclusion of the meeting. \\n \"The government has given the green light to the Covid pass and preparations will continue,\" Marin added. \\n Minister of Economic Affairs  Mika Lintilä  (Cen) told reporters immediately after the meeting that there was broad agreement between the coalition parties over the need for the certificate. \\n \"It [the pass] is an important tool so that we will not need restrictions any more,\" Lintilä said. \\n The government also decided at Thursday afternoon\\'s meeting to offer coronavirus vaccines to all 12- to 15-year-olds, starting as early as next week. \\n \"Fortunately, we have received an extra batch of approximately 200,000 doses of vaccine in Finland, from which these vaccinations [for 12- to 15-year-olds] can be started without interfering with other vaccination programmes,\" Marin told Yle\\'s A-studio on Wednesday evening. \\n Restrictions for bars, restaurants in spreading regions \\n Furthermore, the government will reintroduce restrictions on the opening hours and operations of bars and restaurants due to the deteriorating coronavirus situation in regions considered to be in the spreading — or most serious — phase of the epidemic. \\n This means that bars and restaurants in the regions of Southwest Finland, Pirkanmaa and Kymenlaakso, as well as the Helsinki metropolitan area, will have to adapt to new regulations that are due to take effect from Sunday. \\n The measures include the opening hours of bars being limited to between 7am and 10pm, while restaurants can stay open one hour later. A ban on karaoke and dancing indoors has also been reintroduced. \\n There will be no changes to the opening hours of bars or restaurants in regions considered to be in the acceleration phase of the pandemic. \\n Changes to external border traffic \\n The government has also decided to make changes to the restrictions on Finland\\'s external border traffic, according to the Ministry of the Interior. External border traffic refers to traffic between Finland and countries not belonging to the Schengen area. \\n The regulations currently in effect will be amended, beginning from 9 August, so that entry restrictions are removed for Ukrainian residents traveling to Finland from Ukraine. \\n Restrictions on entry will be restored for residents of Azerbaijan, South Korea, Japan, Moldova, Serbia and Singapore travelling from these countries to Finland. \\n If a person arriving from the above-mentioned countries has not received a full series of vaccinations, the permitted entry criteria are a resident returning to Finland or other EU or Schengen countries, transit of regular scheduled flight traffic at the airport, or other essential reasons. \\n A person can travel to Finland from any country by presenting an acceptable certificate of the full vaccination series. \\n These new regulations aside, the restrictions that entered into force on 19 July still apply. \\n The latest restrictions are in effect until 22 August. \\n Protesters demand \"same rules for all\" \\n A small but vocal group of protestors, representing cultural sector workers, gathered near the House of the Estates while the government meeting was ongoing to demonstrate against coronavirus restrictions, demanding a fairer distribution of measures. \\n Restrictions have hit especially hard on the cultural and event industry, with many workers in the sector unable to work for the past year and a half. At the same time, the protestors pointed out, shopping malls have been allowed to operate as normal. \\n \"Same rules for all,\" the protesters chanted.', 'timestamp': datetime.datetime(2021, 8, 5, 14, 58, 29), 'title': 'Government opens vaccinations for 12-15-year-olds, gives green light to Covid pass', 'url': 'https://yle.fi/uutiset/12048911'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njXD5XJC-gDR",
        "outputId": "ddd079dc-ce88-4d8b-f5d6-355dd29f3d74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['summary', 'tags', 'text', 'timestamp', 'title', 'url'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = sum(len(text.split()) for text in dataset['train']['text'])\n",
        "\n",
        "print(f\"Total words: {total_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUQr3FtV9zgn",
        "outputId": "9820e132-6bad-4ee8-8253-d937be0f8332"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 475975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What NLP tasks could the dataset be used for?\n",
        "Quite a few takses could be done such as text classification, sentiment analysis, text summarization, and named entity recognition.\n",
        "\n",
        "What features does the dataset have?\n",
        "Summary, tag, text, timestamp, title, and url.\n",
        "\n",
        "How many space-separated words do the texts of the dataset contain in total?\n",
        "Total words: 475975"
      ],
      "metadata": {
        "id": "vifatgRz9SIY"
      }
    }
  ]
}