{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfK7RPt8I6JfShGX3eVd5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Textual-Data-Analysis-25/blob/main/Exercise_task_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This (somewhat doomsday) paper summarizes a set of experiments on LLMs which take what we saw on the lecture a step further to achieve a particular outcome: https://arxiv.org/pdf/2412.12140 . Read the paper (including the fascinating appendix) and ponder the following:"
      ],
      "metadata": {
        "id": "pvU1iq5yPM9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) The complexity and structure of the agent scaffolding, detailed in Fig 3 and the surrounding discussion. How does this relate to what we discussed about prompts as discussed during the lecture?\n",
        "\n",
        "A model consist of thinking steps namely explanation, gaps, findings, plans, and actions.\n",
        "Comment execution for interactig to the system.Memory also give opportunity to go over the history and have multiple steps.\n",
        "Considering advanced prompting:\n",
        "- CoT: The AI iteratively plans, checks gaps, and updates its reasoning, similar to CoT with self-consistency.\n",
        "- Tree-of-Thoughts: The system follows a branching approach where it explores multiple options.\n",
        "- Graph-of-Thoughts: The AI maintains dependencies between its steps, ensuring a structured exploration of potential solutions."
      ],
      "metadata": {
        "id": "aojkhF-gPUww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Given what you know about dspy, do you think it would be very difficult to replicate the experiment in this paper?\n",
        "\n",
        "ti would be hard to achieve replicaiton as also article achieved an over 50% successful self-replication ratio. Challenges could be mentioned as:\n",
        "- Implementing the long-horizon execution loop where the AI dynamically updates its plan based on system feedback.\n",
        "- Providing robust command execution capabilities that allow the AI to interact with the environment.\n",
        "- Ensuring proper state tracking and memory mechanisms to maintain situational awareness.\n",
        "Although replicating reached the good capabilities, it still requires more improvement."
      ],
      "metadata": {
        "id": "pdgukIIdPO4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Does in your view the paper warrant the alarming conclusions?\n",
        "\n",
        "AI self replication could be dangerous and endange the future of digital world or language as self-replicated AI could proliferate the digital world and act against the humanity and human atempts. IT could get a degree of autonomy to improve itself and compete people knowledge. However, it still takes time to get the fully replicator model."
      ],
      "metadata": {
        "id": "l3wGtaitPQCu"
      }
    }
  ]
}